{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbnascent_initial_build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a script for initially building dbnascent from metadata\n",
    "### See dbnascent_update for updating existing database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import sqlalchemy as sql\n",
    "import zipfile as zp\n",
    "import re\n",
    "#from . import utils #(in script)\n",
    "#from . import orm #(in script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import utilities (in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ORM (in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load orm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = utils.load_config(\"/home/lsanford/Documents/data/repositories/dbnascent_build/config.txt\")\n",
    "config = load_config(\"/home/lsanford/Documents/data/repositories/dbnascent_build/config.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables in database if they don't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = config[\"file_locations\"][\"database\"]\n",
    "\n",
    "#utils.update_tables(db_url)\n",
    "update_tables(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse pre-created genome table and load into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism_keys = list(dict(config[\"organism keys\"]).values())\n",
    "\n",
    "#organism_table = utils.get_unique_table(\"organism_table\",organism_keys)\n",
    "organism_table = get_unique_table(\"organism_table\",organism_keys)\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(organism_table)):\n",
    "        entry = organismInfo(\n",
    "            organism = organism_table[i][config[\"organism keys\"][\"organism\"]],\n",
    "            genome_build = organism_table[i][config[\"organism keys\"][\"genome_build\"]],\n",
    "            genome_bases = organism_table[i][config[\"organism keys\"][\"genome_bases\"]],\n",
    "        )\n",
    "        session.merge(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse metadata table and load exptMetadata values into DB, creating expt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_keys = list(dict(config[\"expt keys\"]).values())\n",
    "\n",
    "#expt_table = utils.get_unique_table(\"metadata\",expt_keys)\n",
    "expt_table = get_unique_table(\"metadata\",expt_keys)\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(expt_table)):\n",
    "        entry = exptMetadata(\n",
    "            srp = expt_table[i][config[\"expt keys\"][\"srp\"]],\n",
    "            protocol = expt_table[i][config[\"expt keys\"][\"protocol\"]],\n",
    "            organism = expt_table[i][config[\"expt keys\"][\"organism\"]],\n",
    "            library = expt_table[i][config[\"expt keys\"][\"library\"]],\n",
    "            spikein = expt_table[i][config[\"expt keys\"][\"spikein\"]],\n",
    "            paper_id = expt_table[i][config[\"expt keys\"][\"paper_id\"]],\n",
    "            published = int(expt_table[i][config[\"expt keys\"][\"published\"]]),\n",
    "            year = expt_table[i][config[\"expt keys\"][\"year\"]],\n",
    "            first_author = expt_table[i][config[\"expt keys\"][\"first_author\"]],\n",
    "            last_author = expt_table[i][config[\"expt keys\"][\"last_author\"]],\n",
    "            doi = expt_table[i][config[\"expt keys\"][\"doi\"]],\n",
    "            curator1 = expt_table[i][config[\"expt keys\"][\"curator1\"]],\n",
    "            curator2 = expt_table[i][config[\"expt keys\"][\"curator2\"]],\n",
    "            other_sr_data = int(expt_table[i][config[\"expt keys\"][\"other_sr_data\"]]),\n",
    "            atac_seq = int(expt_table[i][config[\"expt keys\"][\"atac_seq\"]]),\n",
    "            rna_seq = int(expt_table[i][config[\"expt keys\"][\"rna_seq\"]]),\n",
    "            chip_seq = int(expt_table[i][config[\"expt keys\"][\"chip_seq\"]]),\n",
    "            three_dim_seq = int(expt_table[i][config[\"expt keys\"][\"three_dim_seq\"]]),\n",
    "            )\n",
    "        session.merge(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse metadata table and load sampleID values into DB, creating sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_keys = list(dict(config[\"sample keys\"]).values())\n",
    "\n",
    "#sample_table = utils.get_unique_table(\"metadata\",sample_keys)\n",
    "sample_table = get_unique_table(\"metadata\",sample_keys)\n",
    "\n",
    "#metatable = utils.table_parse(config[\"file_locations\"][\"metadata\"])\n",
    "#srz_list = np.array(utils.key_grab(metatable, [config[\"sample keys\"][\"sample_name\"]]))\n",
    "metatable = table_parse(config[\"file_locations\"][\"metadata\"])\n",
    "srz_list = np.array(key_grab(metatable, [config[\"sample keys\"][\"sample_name\"]]))\n",
    "srz_list = np.unique(srz_list[srz_list != \"\"])\n",
    "srz_table = dict(zip(srz_list,list(range(1,len(srz_list)+1))))\n",
    "\n",
    "z = len(srz_table) + 1\n",
    "for i in range(len(sample_table)):\n",
    "    if sample_table[i][config[\"sample keys\"][\"sample_name\"]] == \"\":\n",
    "        sample_table[i][\"sample_id\"] = z\n",
    "        sample_table[i][config[\"sample keys\"][\"sample_name\"]] = sample_table[i][config[\"sample keys\"][\"srr\"]]\n",
    "        z = z + 1\n",
    "    else:\n",
    "        sample_table[i][\"sample_id\"] = srz_table[sample_table[i][config[\"sample keys\"][\"sample_name\"]]]\n",
    "        \n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(sample_table)):\n",
    "        entry = sampleID(\n",
    "            sample_id = sample_table[i][\"sample_id\"],\n",
    "            srr = sample_table[i][config[\"sample keys\"][\"srr\"]],\n",
    "            sample_name = sample_table[i][config[\"sample keys\"][\"sample_name\"]],\n",
    "            )\n",
    "        session.merge(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse metadata table and load geneticInfo values into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_keys = list(dict(config[\"genetic keys\"]).values())\n",
    "\n",
    "#genetic_table = utils.get_unique_table(\"metadata\",genetic_keys)\n",
    "genetic_table = get_unique_table(\"metadata\",genetic_keys)\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(genetic_table)):\n",
    "        genetic = geneticInfo(\n",
    "            organism = genetic_table[i][config[\"genetic keys\"][\"organism\"]],\n",
    "            cell_type = genetic_table[i][config[\"genetic keys\"][\"cell_type\"]],\n",
    "            strain = genetic_table[i][config[\"genetic keys\"][\"strain\"]],\n",
    "            genotype = genetic_table[i][config[\"genetic keys\"][\"genotype\"]],\n",
    "            construct = genetic_table[i][config[\"genetic keys\"][\"construct\"]],\n",
    "            )\n",
    "        session.merge(genetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse metadata table and load conditionInfo values into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_keys = list(dict(config[\"condition keys\"]).values())\n",
    "\n",
    "#condition_table = utils.get_unique_table(\"conditions\",condition_keys)\n",
    "condition_table = get_unique_table(\"conditions\",condition_keys)\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(condition_table)):\n",
    "        if not condition_table[i][\"end time\"]:\n",
    "            duration = \"\"\n",
    "        else:\n",
    "            duration = int(condition_table[i][\"end time\"]) - int(condition_table[i][\"start time\"])\n",
    "            \n",
    "        condition = conditionInfo(\n",
    "            condition_type = condition_table[i][config[\"condition keys\"][\"condition_type\"]],\n",
    "            treatment = condition_table[i][config[\"condition keys\"][\"treatment\"]],\n",
    "            conc_intens = condition_table[i][config[\"condition keys\"][\"conc_intens\"]],\n",
    "            start_time = condition_table[i][config[\"condition keys\"][\"start_time\"]],\n",
    "            end_time = condition_table[i][config[\"condition keys\"][\"end_time\"]],\n",
    "            duration = duration,\n",
    "            time_unit = condition_table[i][config[\"condition keys\"][\"time_unit\"]],\n",
    "            )\n",
    "        session.merge(condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create exptCondition equivalencies in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull condition info including ID from database and make a unique hash for conditions\n",
    "\n",
    "condition_id = []\n",
    "condition_details = []\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for row in session.query(conditionInfo).all():\n",
    "        condition_id.append(row.condition_id)\n",
    "        condition_details.append(\"\".join([str(row.condition_type),\n",
    "                                         str(row.treatment),\n",
    "                                         str(row.conc_intens),\n",
    "                                         str(row.start_time),\n",
    "                                         str(row.end_time),\n",
    "                                         str(row.time_unit)]))\n",
    "\n",
    "condition_dict = dict(zip(condition_details,condition_id))\n",
    "\n",
    "# Pull sample ID from database for each SRR\n",
    "\n",
    "srr = []\n",
    "sample_id = []\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for row in session.query(sampleID).all():\n",
    "        srr.append(row.srr)\n",
    "        sample_id.append(row.sample_id)\n",
    "        \n",
    "sample_dict = dict(zip(srr,sample_id))\n",
    "\n",
    "# Grab condition table including SRRs and make SRR/condition hash\n",
    "\n",
    "condition_keys = list(dict(config[\"condition keys\"]).values())\n",
    "condition_keys.append(\"srr\")\n",
    "#condition_table = utils.table_parse(config[\"file_locations\"][\"conditions\"])\n",
    "#cond_str = utils.key_grab(condition_table,condition_keys)\n",
    "condition_table = table_parse(config[\"file_locations\"][\"conditions\"])\n",
    "cond_str = key_grab(condition_table,condition_keys)\n",
    "\n",
    "srr_cond = []\n",
    "for i in range(len(cond_str)):\n",
    "    srr_cond.append([cond_str[i][-1],\"\".join(cond_str[i][0:-1])])\n",
    "\n",
    "srr_cond = np.unique(np.array(srr_cond),axis=0)\n",
    "\n",
    "# Make sample ID/condition ID table\n",
    "sample_condition = []\n",
    "for i in range(len(srr_cond)):\n",
    "    sample_id = sample_dict[srr_cond[i][0]]\n",
    "    condition = condition_dict[srr_cond[i][1]]\n",
    "    sample_condition.append([sample_id,condition])\n",
    "\n",
    "sample_condition = np.unique(np.array(sample_condition),axis=0)\n",
    "\n",
    "# Add to database\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(sample_condition)):\n",
    "        statement = exptCondition.insert().values(sample_id=int(sample_condition[i][0]), \n",
    "                                                  condition_id=int(sample_condition[i][1]))\n",
    "        session.execute(statement)\n",
    "        session.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build sampleAccum table and linker table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add relevant DB keys to table in correct rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metatable = utils.table_parse(config[\"file_locations\"][\"metadata\"])\n",
    "metatable = table_parse(config[\"file_locations\"][\"metadata\"])\n",
    "\n",
    "# Do some data massaging\n",
    "for i in range(len(metatable)):\n",
    "    metatable[i][\"year\"] = int(metatable[i][\"year\"])\n",
    "    metatable[i][\"replicate\"] = metatable[i][\"replicate\"][0:4]\n",
    "    if not metatable[i][config[\"sample keys\"][\"sample_name\"]]:\n",
    "        metatable[i][config[\"sample keys\"][\"sample_name\"]] = metatable[i][config[\"sample keys\"][\"srr\"]]\n",
    "    for key in metatable[i]:\n",
    "        if metatable[i][key] == '0':\n",
    "            metatable[i][key] = False\n",
    "        elif metatable[i][key] == '1':\n",
    "            metatable[i][key] = True\n",
    "\n",
    "# Add sample id\n",
    "sample_keys = dict(config[\"sample keys\"])\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for row in session.query(sampleID).all():\n",
    "        db_row = object_as_dict(row)\n",
    "        for i in range(len(metatable)):\n",
    "            if value_compare(db_row,metatable[i],sample_keys):\n",
    "                metatable[i][\"sample_id\"] = row.sample_id\n",
    "                metatable[i][\"sample_name\"] = row.sample_name\n",
    "\n",
    "# Add genetic id\n",
    "genetic_keys = dict(config[\"genetic keys\"])\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for row in session.query(geneticInfo).all():\n",
    "        db_row = object_as_dict(row)\n",
    "        for i in range(len(metatable)):\n",
    "            if value_compare(db_row,metatable[i],genetic_keys):\n",
    "                metatable[i][\"genetic_id\"] = row.genetic_id         \n",
    "\n",
    "# Add experimental id                \n",
    "expt_keys = dict(config[\"expt keys\"])\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for row in session.query(exptMetadata).all():\n",
    "        db_row = object_as_dict(row)\n",
    "        for i in range(len(metatable)):\n",
    "            if value_compare(db_row,metatable[i],expt_keys):\n",
    "                metatable[i][\"expt_id\"] = row.expt_id\n",
    "                \n",
    "# Collapse table to unique values based on sample_id (combines SRZs, essentially)\n",
    "metatable = list({v['sample_id']:v for v in metatable}.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make linkIDs table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(metatable)):\n",
    "        entry = linkIDs(\n",
    "            sample_id = metatable[i][\"sample_id\"],\n",
    "            genetic_id = metatable[i][\"genetic_id\"],\n",
    "            expt_id = metatable[i][\"expt_id\"],\n",
    "        )\n",
    "        session.merge(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load database data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = config[\"file_locations\"][\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape FastQC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metatable)):\n",
    "    paper_id = metatable[i][config[\"expt keys\"][\"paper_id\"]]\n",
    "    sample = metatable[i][\"sample_name\"]\n",
    "    dirpath = data_path + paper_id + \"/qc/fastqc/zips/\"\n",
    "    \n",
    "    if metatable[i][config[\"accum keys\"][\"single_paired\"]] == \"paired\":\n",
    "        samp_zip = dirpath + sample + \"_1_fastqc\"\n",
    "    else:\n",
    "        samp_zip = dirpath + sample + \"_fastqc\"\n",
    "\n",
    "    if not (\n",
    "        os.path.exists(samp_zip + \".zip\")\n",
    "    ):\n",
    "        continue\n",
    "        \n",
    "    with zp.ZipFile(samp_zip + \".zip\", 'r') as zp_ref:\n",
    "        zp_ref.extractall(dirpath)\n",
    "\n",
    "    fdata = open(samp_zip + \"/fastqc_data.txt\")\n",
    "    for line in fdata:\n",
    "        if re.compile(\"Total Sequences\").search(line):\n",
    "            metatable[i][\"raw_read_depth\"] = int(line.split()[2])\n",
    "        if re.compile(\"Sequence length\").search(line):\n",
    "            metatable[i][\"raw_read_length\"] = int(line.split()[2].split(\"-\")[0])\n",
    "\n",
    "    shutil.rmtree(samp_zip)\n",
    "\n",
    "    if metatable[i][config[\"accum keys\"][\"rcomp\"]] == 1:\n",
    "        if metatable[i][config[\"accum keys\"][\"single_paired\"]] == \"paired\":\n",
    "            samp_zip = dirpath + sample + \"_1.flip.trim_fastqc\"\n",
    "        else:\n",
    "            samp_zip = dirpath + sample + \".flip.trim_fastqc\"\n",
    "    else:\n",
    "        if metatable[i][config[\"accum keys\"][\"single_paired\"]] == \"paired\":\n",
    "            samp_zip = dirpath + sample + \"_1.trim_fastqc\"\n",
    "        else:\n",
    "            samp_zip = dirpath + sample + \".trim_fastqc\"\n",
    "    \n",
    "    with zp.ZipFile(samp_zip + \".zip\", 'r') as zp_ref:\n",
    "        zp_ref.extractall(dirpath)\n",
    "\n",
    "    fdata = open(samp_zip + \"/fastqc_data.txt\")\n",
    "    for line in fdata:\n",
    "        if re.compile(\"Total Sequences\").search(line):\n",
    "            metatable[i][\"trim_read_depth\"] = int(line.split()[2])\n",
    "\n",
    "    shutil.rmtree(samp_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape picardtools data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metatable)):\n",
    "    paper_id = metatable[i][config[\"expt keys\"][\"paper_id\"]]\n",
    "    sample = metatable[i][\"sample_name\"]    \n",
    "    dirpath = data_path + paper_id + \"/qc/picard/dups/\"\n",
    "    filepath = dirpath + sample + \".marked_dup_metrics.txt\"\n",
    "    \n",
    "    if not (\n",
    "        os.path.exists(filepath) and os.path.isfile(filepath)\n",
    "    ):\n",
    "        continue\n",
    "        \n",
    "    fdata = open(filepath)\n",
    "    for line in fdata:\n",
    "        if re.compile(\"Unknown Library\").search(line):\n",
    "            metatable[i][\"duplication_picard\"] = float(line.split(\"\\t\")[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape mapping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metatable)):\n",
    "    paper_id = metatable[i][config[\"expt keys\"][\"paper_id\"]]\n",
    "    sample = metatable[i][\"sample_name\"]    \n",
    "    dirpath = data_path + paper_id + \"/qc/hisat2_mapstats/\"\n",
    "    filepath = dirpath + sample + \".hisat2_mapstats.txt\"\n",
    "    \n",
    "    if not (\n",
    "        os.path.exists(filepath) and os.path.isfile(filepath)\n",
    "    ):\n",
    "        continue\n",
    "        \n",
    "    fdata = open(filepath)\n",
    "    if metatable[i][config[\"accum keys\"][\"single_paired\"]] == \"paired\":\n",
    "        for line in fdata:\n",
    "            if re.compile(\"concordantly 1 time\").search(line):\n",
    "                reads = int(line.split(\": \")[1].split(\" (\")[0]) * 2\n",
    "            if re.compile(\"Aligned 1 time\").search(line):    \n",
    "                metatable[i][\"single_map\"] = reads + int(line.split(\": \")[1].split(\" (\")[0])\n",
    "            if re.compile(\"concordantly >1 times\").search(line):\n",
    "                reads = int(line.split(\": \")[1].split(\" (\")[0]) * 2\n",
    "            if re.compile(\"Aligned >1 times\").search(line):\n",
    "                metatable[i][\"multi_map\"] = reads + int(line.split(\": \")[1].split(\" (\")[0])\n",
    "            if re.compile(\"Overall alignment rate\").search(line):\n",
    "                metatable[i][\"map_prop\"] = float(line.split(\": \")[1].split(\"%\")[0])/100\n",
    "    else:\n",
    "        for line in fdata:\n",
    "            if re.compile(\"Aligned 1 time\").search(line):\n",
    "                metatable[i][\"single_map\"] = int(line.split(\": \")[1].split(\" (\")[0])\n",
    "            if re.compile(\"Aligned >1 times\").search(line):\n",
    "                metatable[i][\"multi_map\"] = int(line.split(\": \")[1].split(\" (\")[0])\n",
    "            if re.compile(\"Overall alignment rate\").search(line):\n",
    "                metatable[i][\"map_prop\"] = float(line.split(\": \")[1].split(\"%\")[0])/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape rseqc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metatable)):\n",
    "    paper_id = metatable[i][config[\"expt keys\"][\"paper_id\"]]\n",
    "    sample = metatable[i][\"sample_name\"] \n",
    "    dirpath = data_path + paper_id + \"/qc/rseqc/read_distribution/\"\n",
    "    filepath = dirpath + sample + \".read_distribution.txt\"\n",
    "    \n",
    "    if not (\n",
    "        os.path.exists(filepath) and os.path.isfile(filepath)\n",
    "    ):\n",
    "        continue\n",
    "        \n",
    "    fdata = open(filepath)\n",
    "    for line in fdata:\n",
    "        if re.compile(\"Total Assigned Tags\").search(line):\n",
    "            metatable[i][\"rseqc_tags\"] = int(line.split()[-1])\n",
    "        if re.compile(\"CDS_Exons\").search(line):\n",
    "            metatable[i][\"rseqc_cds\"] = int(line.split()[2])\n",
    "            metatable[i][\"cds_rpk\"] = float(line.split()[-1])\n",
    "        if re.compile(\"5'UTR_Exons\").search(line):\n",
    "            metatable[i][\"rseqc_five_utr\"] = int(line.split()[2])\n",
    "        if re.compile(\"3'UTR_Exons\").search(line):\n",
    "            metatable[i][\"rseqc_three_utr\"] = int(line.split()[2])\n",
    "        if re.compile(\"Introns\").search(line):\n",
    "            metatable[i][\"rseqc_intron\"] = int(line.split()[2])\n",
    "            metatable[i][\"intron_rpk\"] = float(line.split()[-1])\n",
    "\n",
    "    metatable[i][\"exint_ratio\"] =  metatable[i][\"cds_rpk\"]/metatable[i][\"intron_rpk\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull preseq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metatable)):\n",
    "    paper_id = metatable[i][config[\"expt keys\"][\"paper_id\"]]\n",
    "    sample = metatable[i][\"sample_name\"]  \n",
    "    dirpath = data_path + paper_id + \"/qc/preseq/\"\n",
    "    filepath = dirpath + sample + \".lc_extrap.txt\"\n",
    "    \n",
    "    if not (\n",
    "        os.path.exists(filepath) and os.path.isfile(filepath)\n",
    "    ):\n",
    "        continue\n",
    "           \n",
    "    fdata = open(filepath)\n",
    "    for line in fdata:\n",
    "        if line.startswith(\"10000000.0\"):\n",
    "            distinct = float(line.split()[1])\n",
    "            \n",
    "    metatable[i][\"distinct_tenmillion_prop\"] = distinct/10000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull pileup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metatable)):\n",
    "    paper_id = metatable[i][config[\"expt keys\"][\"paper_id\"]]\n",
    "    sample = metatable[i][\"sample_name\"]\n",
    "    dirpath = data_path + paper_id + \"/qc/pileup/\"\n",
    "    filepath = dirpath + sample + \".coverage.stats.txt\"\n",
    "    \n",
    "    if not (\n",
    "        os.path.exists(filepath) and os.path.isfile(filepath)\n",
    "    ):\n",
    "        continue\n",
    "         \n",
    "    fdata = open(filepath)\n",
    "    x = 0\n",
    "    total = cov = fold = 0\n",
    "    for line in fdata:\n",
    "        if x == 0:\n",
    "            x = x + 1\n",
    "            continue\n",
    "        else:\n",
    "            x = x + 1\n",
    "            total = total + int(line.split(\"\\t\")[2])\n",
    "            cov = cov + int(line.split(\"\\t\")[5])\n",
    "            fold = fold + float(line.split(\"\\t\")[1])*int(line.split(\"\\t\")[2])\n",
    "        \n",
    "    metatable[i][\"genome_prop_cov\"] = cov/total\n",
    "    metatable[i][\"avg_fold_cov\"] = fold/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_keys = list(dict(config[\"accum keys\"]).values())\n",
    "\n",
    "#with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url = \"sqlite:///\" + db_url) as session:\n",
    "    for i in range(len(metatable)):\n",
    "        entry = sampleAccum(\n",
    "            sample_id = metatable[i][\"sample_id\"],\n",
    "            replicate = metatable[i][config[\"accum keys\"][\"replicate\"]],\n",
    "            single_paired = metatable[i][config[\"accum keys\"][\"single_paired\"]],\n",
    "            rcomp = metatable[i][config[\"accum keys\"][\"rcomp\"]],\n",
    "            raw_read_depth = metatable[i][\"raw_read_depth\"],\n",
    "            trim_read_depth = metatable[i][\"trim_read_depth\"],\n",
    "            raw_read_length = metatable[i][\"raw_read_length\"],\n",
    "            duplication_picard = metatable[i][\"duplication_picard\"],\n",
    "            single_map = metatable[i][\"single_map\"],\n",
    "            multi_map = metatable[i][\"multi_map\"],\n",
    "            map_prop = metatable[i][\"map_prop\"],\n",
    "            rseqc_tags = metatable[i][\"rseqc_tags\"],\n",
    "            rseqc_cds = metatable[i][\"rseqc_cds\"],\n",
    "            rseqc_five_utr = metatable[i][\"rseqc_five_utr\"],\n",
    "            rseqc_three_utr = metatable[i][\"rseqc_three_utr\"],\n",
    "            rseqc_intron = metatable[i][\"rseqc_intron\"],\n",
    "            cds_rpk = metatable[i][\"cds_rpk\"],\n",
    "            intron_rpk = metatable[i][\"intron_rpk\"],\n",
    "            exint_ratio = metatable[i][\"exint_ratio\"],\n",
    "            distinct_tenmillion_prop = metatable[i][\"distinct_tenmillion_prop\"],\n",
    "            genome_prop_cov = metatable[i][\"genome_prop_cov\"],\n",
    "            avg_fold_cov = metatable[i][\"avg_fold_cov\"],\n",
    "        )\n",
    "        session.merge(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
