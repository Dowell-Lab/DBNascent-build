{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query_printout.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This allows a user to make a query and print out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import sqlalchemy as sql\n",
    "\n",
    "# from . import utils #(in script)\n",
    "# from . import orm #(in script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_fields = [\"cell_type\"]\n",
    "user_input_filters = {\"organism\": [\"= \\\"H. sapiens\\\"\"],\n",
    "                      \"fcgene_date\": [\"not null\"],\n",
    "                      \"baseline_control_expt\": [\"in (\\\"control\\\",\\\"baseline\\\")\"]}\n",
    "#                      \"cell_type\": [\"in (\\\"ESC\\\",\\\"HeLa\\\")\"]}\n",
    "outfile = \"/home/lsanford/Desktop/db_query_human_control_baseline.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load utils.py\n",
    "# utils.py --- Utilities for simplifying database code\n",
    "#\n",
    "# Filename: utils.py\n",
    "# Description: Miscellaneous utilities for simplifying database code\n",
    "# Author: Zachary Maas <zama8258@colorado.edu> and Lynn Sanford\n",
    "# Maintainer: Lynn Sanford <lynn.sanford@colorado.edu>\n",
    "# Created: Mon Jul  1 16:04:05 2019 (-0600)\n",
    "#\n",
    "\n",
    "# Commentary:\n",
    "#\n",
    "# This module contains a few helpful utility functions and classes for\n",
    "# reducing the total amount of code needed for the database, since\n",
    "# there are many areas where the same patterns keep popping up.\n",
    "#\n",
    "\n",
    "# Code:\n",
    "\n",
    "import os\n",
    "import configparser\n",
    "import sqlalchemy as sql\n",
    "import csv\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "\n",
    "# Database Connection Handler\n",
    "class NascentDBConnection:\n",
    "    engine = None\n",
    "    _Session = None\n",
    "    session = None\n",
    "\n",
    "    def __init__(self, db_url):\n",
    "        self.engine = sql.create_engine(db_url, echo=False)\n",
    "        self.Session = sessionmaker(bind=self.engine)\n",
    "        self.session = self.Session()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.session\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.session.commit()\n",
    "        self.engine.dispose()\n",
    "\n",
    "\n",
    "# Configuration File Reader\n",
    "def load_config(filename: str):\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(\n",
    "            \"Configuration file does not exist at the provided path\"\n",
    "        )\n",
    "    config = configparser.ConfigParser()\n",
    "    with open(filename) as confFile:\n",
    "        config.read_string(confFile.read())\n",
    "    return config\n",
    "\n",
    "\n",
    "# Add/update (?) tables in database\n",
    "# (I'm not actually sure this updates if already existing)\n",
    "\n",
    "\n",
    "def update_tables(db_url: str) -> None:\n",
    "    engine = sql.create_engine(\"sqlite:///\" + db_url, echo=False)\n",
    "    Base.metadata.create_all(engine, checkfirst=True)\n",
    "\n",
    "\n",
    "# Function for parsing table into list of dicts\n",
    "def table_parse(table_filepath: str) -> list:\n",
    "    \"\"\"Parse table into list of dicts.\n",
    "\n",
    "    Takes the manually curated metadata table as input and\n",
    "    turns it into a list of dicts, one entry for each srr with\n",
    "    key: value pairs for each column in the metadata table\n",
    "    Output: List of dicts\n",
    "    \"\"\"\n",
    "    # Check that the table file exists\n",
    "    if not (os.path.exists(table_filepath) and os.path.isfile(table_filepath)):\n",
    "        raise FileNotFoundError(f\"{table_filepath} does not exist.\")\n",
    "\n",
    "    # Load in file as a list of dicts\n",
    "    table_list = []\n",
    "    with open(table_filepath, newline=\"\") as tab:\n",
    "        full_table = csv.DictReader(tab, delimiter=\"\\t\")\n",
    "        for entry in full_table:\n",
    "            table_list.append(dict(entry))\n",
    "\n",
    "    return table_list\n",
    "\n",
    "\n",
    "# Function for grabbing specific keys\n",
    "def key_grab(table_list, key_list) -> list:\n",
    "    \"\"\"Grab specific key values.\n",
    "\n",
    "    Takes list of dicts and a list of keys and\n",
    "    extracts specific values to a list for inputting into database\n",
    "    Output: List of values corresponding to input keys for each\n",
    "    table entry\n",
    "    \"\"\"\n",
    "    # Load in file as a list of dicts\n",
    "    value_list = []\n",
    "    for entry in table_list:\n",
    "        value_subset = []\n",
    "        for i in range(len(key_list)):\n",
    "            value_subset.append(entry[key_list[i]])\n",
    "        value_list.append(value_subset)\n",
    "\n",
    "    return value_list\n",
    "\n",
    "\n",
    "def get_unique_table(location_key, column_keys) -> dict:\n",
    "    filepath = config[\"file_locations\"][location_key]\n",
    "    full_table_dict = table_parse(filepath)\n",
    "\n",
    "    full_table_list = np.array(key_grab(full_table_dict, column_keys))\n",
    "    unique_list = np.unique(full_table_list, axis=0)\n",
    "\n",
    "    unique_table = []\n",
    "    for i in range(len(unique_list)):\n",
    "        entry = dict(zip(column_keys, unique_list[i]))\n",
    "        unique_table.append(entry)\n",
    "\n",
    "    return unique_table\n",
    "\n",
    "\n",
    "def value_compare(db_row, metatable_row, key_dict) -> bool:\n",
    "    for key in key_dict:\n",
    "        if db_row[key] == metatable_row[key_dict[key]]:\n",
    "            continue\n",
    "        else:\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "def object_as_dict(obj):\n",
    "    return {c.key: getattr(obj, c.key) for c\n",
    "            in sql.inspect(obj).mapper.column_attrs}\n",
    "\n",
    "\n",
    "#\n",
    "# utils.py ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = utils.load_config(\"/home/lsanford/Documents/data/repositories/dbnascent_build/config.txt\")\n",
    "config = load_config(\n",
    "    \"/home/lsanford/Documents/data/repositories/DBNascent-build/config.txt\"\n",
    ")\n",
    "db_url = config[\"file_locations\"][\"database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load orm.py\n",
    "# orm.py --- ORM for DBNascent\n",
    "#\n",
    "# Filename: orm.py\n",
    "# Description: ORM for DBNascent\n",
    "# Authors: Zach Maas and Lynn Sanford\n",
    "# Maintainer: Lynn Sanford <lynn.sanford@colorado.edu>\n",
    "# Created: Mon Jun 10 13:11:55 2019 (-0600)\n",
    "# URL:\n",
    "#\n",
    "\n",
    "# Commentary:\n",
    "#\n",
    "# This file contains code for an ORM to interface with the Dowell\n",
    "# Lab's Nascent Database.\n",
    "#\n",
    "\n",
    "# Code:\n",
    "\n",
    "import sqlalchemy as sql\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "# Base class for our ORM\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "# MAIN TABLES\n",
    "class organismInfo(Base):\n",
    "    __tablename__ = \"organismInfo\"\n",
    "    organism = sql.Column(\n",
    "        sql.String(length=127), primary_key=True, index=True, unique=True\n",
    "    )\n",
    "    genome_build = sql.Column(sql.String(length=50))\n",
    "    genome_bases = sql.Column(sql.Integer)\n",
    "\n",
    "#    def __repr__(self):\n",
    "#        return f\"organismInfo(genome_build={self.genome_build!r}, genome_bases={self.genome_bases!r})\"\n",
    "\n",
    "\n",
    "class searchEq(Base):\n",
    "    __tablename__ = \"searchEq\"\n",
    "    search_term = sql.Column(\n",
    "        sql.String(length=250), primary_key=True, index=True, unique=True\n",
    "    )\n",
    "    db_term = sql.Column(sql.String(length=127))\n",
    "\n",
    "\n",
    "class exptMetadata(Base):\n",
    "    __tablename__ = \"exptMetadata\"\n",
    "    expt_id = sql.Column(sql.Integer,\n",
    "                         primary_key=True,\n",
    "                         index=True,\n",
    "                         unique=True)\n",
    "    srp = sql.Column(sql.String(length=50))\n",
    "    protocol = sql.Column(sql.String(length=50))\n",
    "    organism = sql.Column(\n",
    "        sql.String(length=127), sql.ForeignKey(\"organismInfo.organism\")\n",
    "    )\n",
    "    library = sql.Column(sql.String(length=50))\n",
    "    spikein = sql.Column(sql.String(length=127))\n",
    "    paper_id = sql.Column(sql.String(length=127))\n",
    "    published = sql.Column(sql.Boolean)\n",
    "    year = sql.Column(sql.Integer)\n",
    "    first_author = sql.Column(sql.String(length=127))\n",
    "    last_author = sql.Column(sql.String(length=127))\n",
    "    doi = sql.Column(sql.String(length=300))\n",
    "    curator1 = sql.Column(sql.String(length=50))\n",
    "    curator2 = sql.Column(sql.String(length=50))\n",
    "    other_sr_data = sql.Column(sql.Boolean)\n",
    "    atac_seq = sql.Column(sql.Boolean)\n",
    "    rna_seq = sql.Column(sql.Boolean)\n",
    "    chip_seq = sql.Column(sql.Boolean)\n",
    "    three_dim_seq = sql.Column(sql.Boolean)\n",
    "    other_seq = sql.Column(sql.Boolean)\n",
    "    paper_qc_score = sql.Column(sql.Float)\n",
    "    paper_data_score = sql.Column(sql.Float)\n",
    "\n",
    "\n",
    "class sampleID(Base):\n",
    "    __tablename__ = \"sampleID\"\n",
    "    srr = sql.Column(sql.String(length=50),\n",
    "                     primary_key=True,\n",
    "                     index=True,\n",
    "                     unique=True)\n",
    "    sample_name = sql.Column(sql.String(length=50))\n",
    "    sample_id = sql.Column(sql.Integer)\n",
    "\n",
    "\n",
    "class geneticInfo(Base):\n",
    "    __tablename__ = \"geneticInfo\"\n",
    "    genetic_id = sql.Column(sql.Integer,\n",
    "                            primary_key=True,\n",
    "                            index=True,\n",
    "                            unique=True)\n",
    "    organism = sql.Column(\n",
    "        sql.String(length=127), sql.ForeignKey(\"organismInfo.organism\")\n",
    "    )\n",
    "    sample_type = sql.Column(sql.String(length=127))\n",
    "    cell_type = sql.Column(sql.String(length=127))\n",
    "    clone_individual = sql.Column(sql.String(length=127))\n",
    "    strain = sql.Column(sql.String(length=127))\n",
    "    genotype = sql.Column(sql.String(length=127))\n",
    "    construct = sql.Column(sql.String(length=127))\n",
    "\n",
    "\n",
    "class conditionInfo(Base):\n",
    "    __tablename__ = \"conditionInfo\"\n",
    "    condition_id = sql.Column(sql.Integer,\n",
    "                              primary_key=True,\n",
    "                              index=True,\n",
    "                              unique=True)\n",
    "    condition_type = sql.Column(sql.String(length=127))\n",
    "    treatment = sql.Column(sql.String(length=127))\n",
    "    conc_intens = sql.Column(sql.String(length=50))\n",
    "    start_time = sql.Column(sql.Integer)\n",
    "    end_time = sql.Column(sql.Integer)\n",
    "    duration = sql.Column(sql.Integer)\n",
    "    time_unit = sql.Column(sql.String(length=50))\n",
    "    duration_unit = sql.Column(sql.String(length=50))\n",
    "\n",
    "\n",
    "exptCondition = sql.Table(\n",
    "    \"exptCondition\",\n",
    "    Base.metadata,\n",
    "    sql.Column(\"sample_id\",\n",
    "               sql.Integer,\n",
    "               sql.ForeignKey(\"sampleID.sample_id\")),\n",
    "    sql.Column(\"condition_id\",\n",
    "               sql.Integer,\n",
    "               sql.ForeignKey(\"conditionInfo.condition_id\")),\n",
    ")\n",
    "\n",
    "\n",
    "class linkIDs(Base):\n",
    "    __tablename__ = \"linkIDs\"\n",
    "    sample_id = sql.Column(\n",
    "        sql.Integer,\n",
    "        sql.ForeignKey(\"sampleID.sample_id\"),\n",
    "        primary_key=True,\n",
    "        index=True,\n",
    "        unique=True,\n",
    "    )\n",
    "    genetic_id = sql.Column(sql.Integer,\n",
    "                            sql.ForeignKey(\"geneticInfo.genetic_id\"))\n",
    "    expt_id = sql.Column(sql.Integer,\n",
    "                         sql.ForeignKey(\"exptMetadata.expt_id\"))\n",
    "\n",
    "\n",
    "class sampleAccum(Base):\n",
    "    __tablename__ = \"sampleAccum\"\n",
    "    sample_id = sql.Column(\n",
    "        sql.Integer,\n",
    "        sql.ForeignKey(\"sampleID.sample_id\"),\n",
    "        primary_key=True,\n",
    "        index=True,\n",
    "        unique=True,\n",
    "    )\n",
    "    replicate = sql.Column(sql.Integer)\n",
    "    single_paired = sql.Column(sql.String(length=50))\n",
    "    rcomp = sql.Column(sql.Boolean)\n",
    "    expt_unusable = sql.Column(sql.Boolean)\n",
    "    timecourse = sql.Column(sql.Boolean)\n",
    "    baseline_control_expt = sql.Column(sql.String(length=50))\n",
    "    notes = sql.Column(sql.String(length=300))\n",
    "    raw_read_depth = sql.Column(sql.Integer)\n",
    "    trim_read_depth = sql.Column(sql.Integer)\n",
    "    raw_read_length = sql.Column(sql.Integer)\n",
    "    duplication_picard = sql.Column(sql.Float)\n",
    "    single_map = sql.Column(sql.Integer)\n",
    "    multi_map = sql.Column(sql.Integer)\n",
    "    map_prop = sql.Column(sql.Float)\n",
    "    rseqc_tags = sql.Column(sql.Integer)\n",
    "    rseqc_cds = sql.Column(sql.Integer)\n",
    "    rseqc_five_utr = sql.Column(sql.Integer)\n",
    "    rseqc_three_utr = sql.Column(sql.Integer)\n",
    "    rseqc_intron = sql.Column(sql.Integer)\n",
    "    cds_rpk = sql.Column(sql.Float)\n",
    "    intron_rpk = sql.Column(sql.Float)\n",
    "    exint_ratio = sql.Column(sql.Float)\n",
    "    distinct_tenmillion_prop = sql.Column(sql.Float)\n",
    "    genome_prop_cov = sql.Column(sql.Float)\n",
    "    avg_fold_cov = sql.Column(sql.Float)\n",
    "    samp_qc_score = sql.Column(sql.Integer)\n",
    "    samp_data_score = sql.Column(sql.Integer)\n",
    "\n",
    "\n",
    "class nascentflowMetadata(Base):\n",
    "    __tablename__ = \"nascentflowMetadata\"\n",
    "    nascentflow_version_id = sql.Column(\n",
    "        sql.Integer, primary_key=True, index=True, unique=True\n",
    "    )\n",
    "    sample_id = sql.Column(sql.Integer, sql.ForeignKey(\"sampleID.sample_id\"))\n",
    "    nascentflow_version = sql.Column(sql.String(length=127))\n",
    "    pipeline_revision_hash = sql.Column(sql.String(length=127))\n",
    "    pipeline_hash = sql.Column(sql.String(length=127))\n",
    "    nascentflow_date = sql.Column(sql.Date)\n",
    "    nascentflow_redo_date = sql.Column(sql.Date)\n",
    "    nextflow_version = sql.Column(sql.String(length=127))\n",
    "    fastqc_version = sql.Column(sql.String(length=127))\n",
    "    bbmap_version = sql.Column(sql.String(length=127))\n",
    "    hisat2_version = sql.Column(sql.String(length=127))\n",
    "    samtools_version = sql.Column(sql.String(length=127))\n",
    "    sratools_version = sql.Column(sql.String(length=127))\n",
    "    preseq_version = sql.Column(sql.String(length=127))\n",
    "    preseq_date = sql.Column(sql.Date)\n",
    "    rseqc_version = sql.Column(sql.String(length=127))\n",
    "    rseqc_date = sql.Column(sql.Date)\n",
    "    java_version = sql.Column(sql.String(length=127))\n",
    "    picard_gc_version = sql.Column(sql.String(length=127))\n",
    "    picard_dups_version = sql.Column(sql.String(length=127))\n",
    "    picard_date = sql.Column(sql.Date)\n",
    "    bedtools_version = sql.Column(sql.String(length=127))\n",
    "    igvtools_version = sql.Column(sql.String(length=127))\n",
    "    seqkit_version = sql.Column(sql.String(length=127))\n",
    "    mpich_version = sql.Column(sql.String(length=127))\n",
    "    gcc_version = sql.Column(sql.String(length=127))\n",
    "    python_version = sql.Column(sql.String(length=127))\n",
    "    numpy_version = sql.Column(sql.String(length=127))\n",
    "\n",
    "\n",
    "class bidirflowMetadata(Base):\n",
    "    __tablename__ = \"bidirflowMetadata\"\n",
    "    bidirflow_version_id = sql.Column(\n",
    "        sql.Integer, primary_key=True, index=True, unique=True\n",
    "    )\n",
    "    sample_id = sql.Column(sql.Integer, sql.ForeignKey(\"sampleID.sample_id\"))\n",
    "    bidirflow_version = sql.Column(sql.String(length=127))\n",
    "    pipeline_revision_hash = sql.Column(sql.String(length=127))\n",
    "    pipeline_hash = sql.Column(sql.String(length=127))\n",
    "    bidirflow_date = sql.Column(sql.Date)\n",
    "    nextflow_version = sql.Column(sql.String(length=127))\n",
    "    samtools_version = sql.Column(sql.String(length=127))\n",
    "    bedtools_version = sql.Column(sql.String(length=127))\n",
    "    mpich_version = sql.Column(sql.String(length=127))\n",
    "    openmpi_version = sql.Column(sql.String(length=127))\n",
    "    gcc_version = sql.Column(sql.String(length=127))\n",
    "    r_version = sql.Column(sql.String(length=127))\n",
    "    rsubread_version = sql.Column(sql.String(length=127))\n",
    "    boost_version = sql.Column(sql.String(length=127))\n",
    "    fstitch_version = sql.Column(sql.String(length=127))\n",
    "    tfit_version = sql.Column(sql.String(length=127))\n",
    "    dreg_version = sql.Column(sql.String(length=127))\n",
    "    dreg_date = sql.Column(sql.Date)\n",
    "    tfit_date = sql.Column(sql.Date)\n",
    "    fcgene_date = sql.Column(sql.Date)\n",
    "\n",
    "\n",
    "# The following were created by Zach and we may or may not use...\n",
    "\n",
    "# class tf(Base):\n",
    "#    __tablename__ = \"tf\"\n",
    "#    tf_id = sql.Column(sql.String(length=127), primary_key=True)\n",
    "#    tf_alias = sql.Column(sql.String(length=127))\n",
    "\n",
    "\n",
    "# class pipeline_status(Base):\n",
    "#    __tablename__ = \"pipeline_status\"\n",
    "#    srr_id = sql.Column(\n",
    "#        sql.String(length=127),\n",
    "#        sql.ForeignKey(\"srr_metadata.srr_id\"),\n",
    "#        primary_key=True,\n",
    "#    )\n",
    "#    fastqc_complete = sql.Column(sql.Boolean)\n",
    "#    bbduk_complete = sql.Column(sql.Boolean)\n",
    "#    hisat2_complete = sql.Column(sql.Boolean)\n",
    "#    samtools_complete = sql.Column(sql.Boolean)\n",
    "#    fastq_dump_complete = sql.Column(sql.Boolean)\n",
    "#    pileup_complete = sql.Column(sql.String(length=127))\n",
    "#    preseq_complete = sql.Column(sql.Boolean)\n",
    "#    rseqc_complete = sql.Column(sql.String(length=127))\n",
    "#    bedtools_complete = sql.Column(sql.Boolean)\n",
    "#    igv_tools_complete = sql.Column(sql.Boolean)\n",
    "#    fstitch_complete = sql.Column(sql.Boolean)\n",
    "#    tfit_complete = sql.Column(sql.Boolean)\n",
    "\n",
    "\n",
    "# class md_score(Base):\n",
    "#    __tablename__ = \"md_score\"\n",
    "#    srr_id = sql.Column(\n",
    "#        sql.String(length=127),\n",
    "#        sql.ForeignKey(\"srr_metadata.srr_id\"),\n",
    "#        primary_key=True,\n",
    "#    )\n",
    "#    tf_id = sql.Column(sql.String, sql.ForeignKey(\"tf.tf_id\"))\n",
    "#    erna_type = sql.Column(sql.String(length=127))\n",
    "#    md_score_expected = sql.Column(sql.Integer)\n",
    "#    md_score_std = sql.Column(sql.Integer)\n",
    "\n",
    "\n",
    "# orm.py ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_join_keys = dict(config[\"query_join keys\"])\n",
    "\n",
    "# Find all table columns and make a dict\n",
    "\n",
    "db_query_names = {}\n",
    "db_filter_names = {}\n",
    "tables_to_join = []\n",
    "db_tables = dict(Base.metadata.tables)\n",
    "for key in db_tables:\n",
    "    for column in user_input_fields:\n",
    "        if column in db_tables[key].columns.keys():\n",
    "            if column not in db_query_names.keys():\n",
    "                db_query_names[column] = (key + \".\" + column)\n",
    "            if key not in tables_to_join:\n",
    "                if key not in query_join_keys[\"existing\"]:\n",
    "                    tables_to_join.append(key)\n",
    "    for filtkey in user_input_filters:\n",
    "        if filtkey in db_tables[key].columns.keys():\n",
    "            if filtkey not in db_filter_names.keys():\n",
    "                db_filter_names[filtkey] = (key + \".\" + filtkey)\n",
    "            if key not in tables_to_join:\n",
    "                if key not in query_join_keys[\"existing\"]:\n",
    "                    tables_to_join.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_build = \"select distinct linkIDs.sample_id, exptMetadata.paper_id, sampleID.sample_name\"\n",
    "for key in db_query_names:\n",
    "    query_build = query_build + \", \" + db_query_names[key]\n",
    "\n",
    "query_build = (query_build + \" from linkIDs \" +\n",
    "               \" inner join exptMetadata on exptMetadata.expt_id = linkIDs.expt_id\" +\n",
    "               \" inner join sampleID on sampleID.sample_id = linkIDs.sample_id\")\n",
    "\n",
    "for tab in tables_to_join:\n",
    "    query_build = (query_build + \" \" + query_join_keys[tab.lower()])\n",
    "\n",
    "i=0\n",
    "for key in user_input_filters.keys():\n",
    "    for value in user_input_filters[key]:\n",
    "        if i == 0:\n",
    "            query_build = (query_build + \" where \" + db_filter_names[key] + \" \" + value)\n",
    "            i = 1\n",
    "        else:\n",
    "            query_build = (query_build + \" and \" + db_filter_names[key] + \" \" + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# with utils.NascentDBConnection(db_url=db_url) as session:\n",
    "with NascentDBConnection(db_url=\"sqlite:///\" + db_url) as session:\n",
    "    results = session.execute(query_build).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outfile, \"w\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(([\"sample_id\", \"paper_id\", \"sample_name\"] + list(db_query_names.keys())))\n",
    "    for data in results:\n",
    "        w.writerow(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
